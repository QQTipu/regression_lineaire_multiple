---
title: 'TP2 : Régression Linéaire Multiple "station"'
author: "Thibaut Fortuné"
date: "11/11/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# 1. Etude descriptive des données

## Importation du jeu de données "station.txt"

```{r}
station <- read.table("station.txt", header = 1)
```

## Sommaire des données

```{r}
head(station)
```

```{r}
plot(station[,1:4])
```

On remarque une dépendance linéaire croissante des **ventes** avec le **nbpompes** et le **nbconc**.
En revanche, le lien du nombre de **ventes** avec le **trafic** est beaucoup plus flou.

## Réalisation d'une ACP

```{r}
library(PCAmixdata)

res <- PCAmix(station[,1:4], graph = FALSE)
```

### Déterminantion du nombres d'axes à retenir

```{r}
round(res$eig, digit = 2)
```
Il est intéressant d'explorer les données sous 2 dimensions qui représenterait presque la totalité de nos 4 variables (3,01 + 0,98), soit 99,65% de l'information.

### Représentation des variables dans un sous espace de dimension 2 

```{r}
par(mfrow = c(1,2))
plot(res, axes = c(1, 2), choice = "cor")
plot(res, axes = c(1, 2), choice = "ind")
```

En regardant le cercle de corrélation, on s'apperçoit que les **ventes** sont corrélées avec le **nbpompes** et le **nbconc** qui sont d'ailleurs très linéaires entre-elles. En revanche, le **trafic** semble impacter les **ventes** d'une façon plus modérée.

### Test de la fiabilité des variables en fonction du nombres de dimension

```{r}
round(res$quanti$cos2, digit = 3)
```
En dimension 1 et 2, nous pourrons représenter nos variable avec une certitude proche de 100%.

# 2. Explication du modèle à trois variables

```{r}
modele <- lm(ventes~nbpompes+nbconc+trafic, data = station)
summary(modele)
```
Ici, nous avons une p-valeur < 5% qui rejette l'H0 : "le modèle est inutile".  
En revanche, seulement le **trafic** est en corrélation avec le modèle. Hors nous avons remarqué précédement que les variables qui expliquent le mieux le nombre de **ventes** sont **nbpompes** et **nbconc**. Ce problème peut être dû à la multicolinéarité de ces deux variables comme vu dans l'analyse ACP. Cette multicolinéarité existante masque la significativité des p-valeurs de nos variables.
De plus, nous remarquons que dans les résidus il y a un extreme minimum à -13,1412 (voir graphiques ci-dessous).  
**Nous allons donc définir un meilleur modèle.**

## Représentation des résidus

```{r}
par(mfrow = c(1, 2))
plot(modele$fitted,modele$residuals)
abline(h=0)
boxplot(modele$residuals)
```

## Retrait de la station qui ne répond pas à la normalité 

### On cherche la station qui ne correspond pas à la normalité des résidus

```{r}
out <- which(modele$residuals < -10)
print(out)
```

La station qui pose problème dans notre modèle est la station 1. Après vérification de la base de données, elle possède un nombre de ventes inférieure à d'autres stations avec des variables **nbpomp**, **nbconc** et **trafic** similaires. Nous pouvons conseiller au Diercteur Marketing de se rendre sur place pour constater d'un potentiel événement exceptionnel sur cette station (travaux...) qui la ferait sortir de la normalité.

### On recrée une base de donées station "propre"

```{r}
station <- station[-out,]
modele <- lm(ventes~nbpompes+nbconc+trafic, data = station)
summary(modele)
```

Avec ce nouveau modèle, néttoyé de l'individu station1 :  
La p-valeur < 5%, qui rejette l'H0 : le modèle est inutile.  
De plus, les variables **nbpompes**, **nbconc** et **trafic** ont aussi une p-valeur < 5%, qui rejette l'H0 : les variables sont utiles au modèle. Néanmoins, le **nbconc** avec une p-valeur de 3,1% semble moins en corrélation avec le modèle que les deux autres variables.

## Définition du modèle à 2 variables

```{r}
drop1(modele)
```

Pour définir un modèle à 2 variables la fonction **drop1()** nous suggère de ne retirer aucune variable au modèle.  
Cependant, comme vu dans le **summary()** du modèle à 3 variables, le **nbconc** a une p-valeur à 3,1% tandis que les les deux autres variables en ont une proche de 0%. De plus, son coefficient est proche de 0.  

Nous allons alors essayer de simplifier ce modèle pour en faire un modèle à 2 variables pour expliquer les **ventes** en fonction du **nbpompes** et du **trafic**. Cette opération n'affectera que très peu le score AIC du modèle qui passera à -55,029.

### Modèle sous forme **ventes**~**nbpompes**+**trafic**

# 3. Etude du nouveau modèle à 2 variables

## a. Analyse des indices de qualité du modèle

```{r}
modele <- lm(ventes~nbpompes+trafic, data = station)
summary(modele)
```

Avec ce nouveau modèle à 2 variables :  
Le R-squared ajusté = 0,9987 est sensiblement le même qu'avec le modèle à trois variables (r-squared ajusté = 0,9988).  
La p-valeur < 5%, donc rejet de l'H0 : le modèle est inutile.  
Les p-valeurs des variables **nbpompes** et **trafic** < 5%, rejet de l'H0 : la vraiable est inutile.  

### Test de normalité Shapiro-Wilk

```{r}
shapiro.test(modele$residuals)
```

La p-valeur > 5%, donc on peut admettre la normalité des résidus du modèle.

## b. Interprétation du signe des coef. de régression du modèle

Notre modèle à 2 variables est de forme : **ventes = 192 + 2,8 * nbpompes + 1,1 * trafic**.  
Chaque pompe supplémentaire peut rapporter 2,8 milliers de litre vendu en plus à une station.  
Chaque millier de voitures (+1 **trafic**) peut rapporter 1,1 millier de litre vendu en plus à une station.  
Aussi, pour qu'une station soit rentable, il faudrait au minimum 192 milliers de litre vendu.  

## c. Prédiction des ventes

### Création de trois nouveaux couples de valeurs (nbpompes & trafic)

```{r}
set.seed(1278)
newstation = data.frame(nbpompes = sample(min(station$nbpompes):max(station$nbpompes),3), trafic = sample(min(station$trafic):max(station$trafic),3))
print(newstation)
```

### Prédiction des ventes pour nos trois couples

```{r}
predict(modele, newstation, interval = "pred", level = 0.95)
```
Avec un **nbpompes** = 10 et un **trafic** = 27 milliers de voiture les **ventes** prévues sont de environ 249 milliers de litre en moyenne.  
Avec un **nbpompes** = 20 et un **trafic** = 11 milliers de voiture les **ventes** prévues sont de environ 260 milliers de litre en moyenne.  
Avec un **nbpompes** = 15 et un **trafic** = 19 milliers de voiture les **ventes** prévues sont de environ 255 milliers de litre en moyenne.

# 4. Modèles linéaires simples vs. Modèle linéaire multiple

## Création de nos trois modèles linéaires simple

**ventes** en fonction du **nbpompes**

```{r}
linsimp1 <- lm(ventes~nbpompes, data = station)
summary(linsimp1)
```

**ventes** en fonction du **nbconc**

```{r}
linsimp2 <- lm(ventes~nbconc, data = station)
summary(linsimp2)
```

**ventes** en fonction du **trafic**

```{r}
linsimp3 <- lm(ventes~trafic, data = station)
summary(linsimp3)
```

## Comparaison avec notre modèle à 2 variables

Premièrement, nous pouvons voir qu'avec trois modèles de régression linéaire simple il est plus compliqué d'expliquer les **ventes** en fonction d'une seule vraiable. En effet, les modèles exprimées en fonction du **nbpompes**, du **nbconc** ou du **trafic** expliquent respectivelent les **ventes** qu'à hauteur de 87,6%, 80,37% et 24,19%.  
Un R² ajusté, au mieux plus 10% inférieur à notre modèle de régression linéaire multiple ayant un R² ajusté expliquant 99,87% des **ventes** en fonction du **nbconc** et du **trafic**.

## Estimation avec nos trois modèles linéaires simples

```{r}
set.seed(1278)
newstation = data.frame(nbpompes = sample(min(station$nbpompes):max(station$nbpompes),3), nbconc = sample(min(station$nbconc):max(station$nbconc),3), trafic = sample(min(station$trafic):max(station$trafic),3))

print("**Prédiction des ventes en fonction du nbpomp**")
predict(linsimp1, newstation, interval = "pred", level = 0.95)
print("** Prédiction des ventes en fonction du nbconc**")
predict(linsimp2, newstation, interval = "pred", level = 0.95)
print("**Prédiction des ventes en fonction du trafic**")
predict(linsimp3, newstation, interval = "pred", level = 0.95)
print("**Prédiction des ventes grâce à notre modèle à 2 variables**")
predict(modele, newstation, interval = "pred", level = 0.95)
```

Nous pouvons de plus constater que nos trois modèles linéaires simples font des prédictions qui ne sont pas fiables. En effet, celles-ci ne correspondent pas à l'intervalle d'erreur des valeurs prédites par notre modèle à 2 variables qui explique pourtant les **ventes** en fonction du **nbpompes** et du **trafic** à hauteur de 99,87%.
